use std::collections::HashSet;
use std::error::Error;
use std::path::{Path, PathBuf};
use std::str::FromStr;
use std::time::Duration;

use notify_debouncer_mini::{DebouncedEventKind, new_debouncer, notify::RecursiveMode};
use serde::{Deserialize, Serialize};
use syndicate_json_canvas_lib::jsoncanvas::{JsonCanvas, NodeId};
use syndicate_json_canvas_lib::{default_process_node, to_syndication_format};
use syndicate_json_canvas_sinks::{JjRepositorySink, SyndicationSink};
use tracing::{debug, error, info};
use tracing_subscriber::EnvFilter;

/// TOML structure for the tracker file
#[derive(Debug, Serialize, Deserialize)]
struct TrackerFile {
    published_node_ids: Vec<String>,
}

/// Tracks which nodes have been published to a specific sink
struct SyndicationTracker {
    /// Path to the TOML tracker file
    path: PathBuf,
    /// In-memory set of published node IDs for O(1) lookup
    published_ids: HashSet<String>,
}

impl SyndicationTracker {
    /// Create a tracker for a canvas file and sink combination
    ///
    /// File naming: `.<canvas-name>.canvas.syndication.<sink-name>.toml`
    fn new(canvas_path: &Path, sink_name: &str) -> Result<Self, Box<dyn Error>> {
        let canvas_dir = canvas_path.parent().ok_or("Canvas path has no parent directory")?;
        let canvas_filename = canvas_path
            .file_name()
            .and_then(|s| s.to_str())
            .ok_or("Invalid canvas filename")?;

        // Build tracker filename: .<canvas-name>.syndication.<sink-name>.toml
        let tracker_filename = format!(".{}.syndication.{}.toml", canvas_filename, sink_name);
        let path = canvas_dir.join(tracker_filename);

        // Load existing tracker or create empty
        let published_ids = if path.exists() {
            let content = std::fs::read_to_string(&path)?;
            let tracker: TrackerFile = toml::from_str(&content)?;
            tracker.published_node_ids.into_iter().collect()
        } else {
            HashSet::new()
        };

        info!(tracker_path = %path.display(), published_count = published_ids.len(), "Loaded tracker");

        Ok(Self { path, published_ids })
    }

    /// Check if a node has already been published
    fn is_published(&self, node_id: &NodeId) -> bool {
        self.published_ids.contains(node_id.as_str())
    }

    /// Mark nodes as published and save to disk
    fn mark_published(&mut self, node_ids: &[NodeId]) -> Result<(), Box<dyn Error>> {
        if node_ids.is_empty() {
            return Ok(());
        }

        for node_id in node_ids {
            self.published_ids.insert(node_id.as_str().to_string());
        }

        let tracker = TrackerFile {
            published_node_ids: self.published_ids.iter().cloned().collect(),
        };

        let toml_content = toml::to_string_pretty(&tracker)?;
        let content_with_header = format!(
            "# Generated by syndicate-json-canvas - Do not edit manually\n\n{}",
            toml_content
        );

        std::fs::write(&self.path, content_with_header)?;
        info!(tracker_path = %self.path.display(), total_published = self.published_ids.len(), "Saved tracker");

        Ok(())
    }
}

// Debounce duration in milliseconds - waits this long after last change before processing
const DEBOUNCE_DURATION_MS: u64 = 500;

// Set to true to see what would happen without actually publishing
const DRY_RUN: bool = false;

fn validate_canvas_path(path: &Path) -> Result<(), &str> {
    if !path.is_file() {
        return Err("Provided path must be a file");
    }
    if path.extension().and_then(|s| s.to_str()) != Some("canvas") {
        return Err("Expect the extension to be .canvas");
    }
    Ok(())
}

/// Process the canvas file and publish only new items
fn process_canvas(
    canvas_path: &Path,
    sink: &mut impl SyndicationSink,
    tracker: &mut SyndicationTracker,
    dry_run: bool,
) {
    let content = match std::fs::read_to_string(canvas_path) {
        Ok(c) => c,
        Err(e) => {
            error!(error = %e, "Failed to read file");
            return;
        }
    };

    let canvas = match JsonCanvas::from_str(&content) {
        Ok(c) => c,
        Err(e) => {
            error!(error = %e, "Failed to parse canvas");
            return;
        }
    };

    let all_items = to_syndication_format(canvas, Some(default_process_node));
    let total_count = all_items.len();
    info!(total_items = total_count, "Found items matching filter");

    // Filter out already-published items
    let new_items: std::collections::HashMap<_, _> = all_items
        .into_iter()
        .filter(|(node_id, _)| !tracker.is_published(node_id))
        .collect();

    let already_published = total_count - new_items.len();
    debug!(
        new_items = new_items.len(),
        already_published = already_published,
        "Filtered to new items only"
    );

    if new_items.is_empty() {
        info!("No new items to publish");
        return;
    }

    info!(
        new_items = new_items.len(),
        "Publishing new items"
    );

    // Collect node IDs before publishing (for tracking)
    let published_ids: Vec<NodeId> = new_items.keys().cloned().collect();

    match sink.publish(&new_items, dry_run) {
        Ok(()) => {
            info!("Successfully published all items");

            // Mark as published (skip in dry-run mode)
            if !dry_run {
                if let Err(e) = tracker.mark_published(&published_ids) {
                    error!(error = %e, "Failed to save tracker");
                }
            }
        }
        Err(e) => error!(error = %e, "Failed to publish items"),
    }
}

/// Watch the canvas file and process changes
fn watch_and_process(
    canvas_path: &Path,
    mut sink: impl SyndicationSink,
    mut tracker: SyndicationTracker,
    dry_run: bool,
) -> Result<(), Box<dyn Error>> {
    // Process on startup
    info!("Processing canvas file on startup...");
    process_canvas(canvas_path, &mut sink, &mut tracker, dry_run);

    // Setup file watcher
    let (tx, rx) = std::sync::mpsc::channel();
    let mut debouncer = new_debouncer(Duration::from_millis(DEBOUNCE_DURATION_MS), tx)?;

    debouncer
        .watcher()
        .watch(canvas_path, RecursiveMode::NonRecursive)?;

    info!("Watching for file changes...");

    for res in rx {
        match res {
            Ok(events) => {
                for event in events {
                    if let DebouncedEventKind::Any = event.kind {
                        info!("File changed, processing...");
                        process_canvas(canvas_path, &mut sink, &mut tracker, dry_run);
                    }
                }
            }
            Err(error) => error!(error = ?error, "Watch error"),
        }
    }

    Ok(())
}

fn main() -> Result<(), Box<(dyn Error)>> {
    // Initialize logging (DEBUG when dry-run, INFO otherwise)
    tracing_subscriber::fmt()
        .with_env_filter(EnvFilter::new(if DRY_RUN { "debug" } else { "info" }))
        .with_line_number(true)
        .with_file(true)
        .with_target(false)
        .init();

    // Setup canvas file path
    let canvas_path = PathBuf::from("/Users/aadalal/Documents/scratchpad/Thoughts.canvas");
    validate_canvas_path(&canvas_path)?;

    // Setup syndication sink
    let jj_sink = JjRepositorySink::new(
        "/Users/aadalal/dev/aadalal.github.io/",
        "main",
        "origin",
        "_tiny_thoughts",
    )?;

    // Setup tracker for deduplication
    let tracker = SyndicationTracker::new(&canvas_path, jj_sink.name())?;

    // Log configuration
    info!(
        canvas_file = %canvas_path.display(),
        debounce_ms = DEBOUNCE_DURATION_MS,
        "Watching canvas file"
    );
    info!(
        sink = jj_sink.name(),
        dry_run = DRY_RUN,
        "Publishing configuration"
    );

    // Start watching and processing
    watch_and_process(&canvas_path, jj_sink, tracker, DRY_RUN)
}
